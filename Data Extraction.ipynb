{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss\n",
    "loss = pd.read_csv('AviationData.txt', sep=\"|\",skipinitialspace=True)\n",
    "filtered_loss = loss.dropna(axis='columns', how='all')\n",
    "#Trimed&Stringallobject\n",
    "filtered_loss_obj = filtered_loss.select_dtypes(['object'])\n",
    "filtered_loss_obj.astype(str)\n",
    "loss[filtered_loss_obj.columns] = filtered_loss_obj.apply(lambda x: x.str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_loss_obj.to_csv('Loss.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpath = []\n",
    "for root, dirs, files in os.walk(r\"C:\\Users\\zlin\\FAA_Zoey\\Data Extraction\", topdown=False):\n",
    "    for file in files:\n",
    "        if file.endswith(\"MASTER.txt\")or file.endswith('MASTER.TXT'):\n",
    "            path = os.path.join(root, file)\n",
    "            mpath.append(path)\n",
    "\n",
    "#Good Format\n",
    "MASTER17 = pd.read_csv(mpath[7], sep = \",\", index_col=False, skipinitialspace = True, dtype=object)\n",
    "MASTER18 = pd.read_csv(mpath[8], sep = \",\", index_col=False, skipinitialspace = True, dtype=object)\n",
    "MASTER19 = pd.read_csv(mpath[9], sep = \",\", index_col=False, skipinitialspace = True, dtype=object)\n",
    "MASTER20 = pd.read_csv(mpath[10], sep = \",\", index_col=False, skipinitialspace = True, dtype=object)\n",
    "\n",
    "#Bad Format\n",
    "MASTER10 = pd.read_csv(mpath[0], names = MASTER20.columns, sep = \",\", index_col=False, skipinitialspace = True, dtype = object)\n",
    "MASTER11 = pd.read_table(mpath[1], names = MASTER20.columns, index_col=False, skipinitialspace = True, dtype = object)\n",
    "MASTER12 = pd.read_table(mpath[2], names = MASTER20.columns, index_col=False, skipinitialspace = True, dtype = object)\n",
    "MASTER13 = pd.read_csv(mpath[3], names = MASTER20.columns, sep = \",\", index_col=False, skipinitialspace = True, dtype = object)\n",
    "MASTER14 = pd.read_table(mpath[4], names = MASTER20.columns, index_col=False, skipinitialspace = True, dtype = object)\n",
    "MASTER15 = pd.read_csv(mpath[5], skiprows = [0], names = MASTER20.columns, sep = \",\", index_col=False, skipinitialspace = True, dtype = object)\n",
    "MASTER16 = pd.read_csv(mpath[6], skiprows = [0], names = MASTER20.columns, sep = \",\", index_col=False, skipinitialspace = True, dtype = object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Marking datasource\n",
    "MASTER10['Exposure Year'] = '2010' \n",
    "MASTER11['Exposure Year'] = '2011'\n",
    "MASTER12['Exposure Year'] = '2012'\n",
    "MASTER13['Exposure Year'] = '2013'\n",
    "MASTER14['Exposure Year'] = '2014'\n",
    "MASTER15['Exposure Year'] = '2015'\n",
    "MASTER16['Exposure Year'] = '2016'\n",
    "MASTER17['Exposure Year'] = '2017'\n",
    "MASTER18['Exposure Year'] = '2018'\n",
    "MASTER19['Exposure Year'] = '2019'\n",
    "MASTER20['Exposure Year'] = '2020'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output=MASTERraw, Concat, Adjusted N-NUMBER, Trimed&String&Upperallobject \n",
    "masters= [MASTER10, MASTER11, MASTER12, MASTER13,MASTER14, MASTER15, MASTER16, MASTER17, MASTER18, MASTER19, MASTER20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASTERraw = pd.concat(masters,ignore_index = True).reset_index(drop=True)\n",
    "MASTERraw.drop(columns='Unnamed: 34',inplace=True)\n",
    "MASTERraw['N-NUMBER'] = 'N' + MASTERraw['N-NUMBER'].astype(str)\n",
    "MASTERraw_obj = MASTERraw.select_dtypes(['object'])\n",
    "MASTERraw[MASTERraw_obj.columns] =MASTERraw_obj.apply(lambda x: x.str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASTERraw.to_csv('MASTER.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dereg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpath = []\n",
    "for root, dirs, files in os.walk(r\"C:\\Users\\zlin\\FAA_Zoey\\Data Extraction\", topdown=False):\n",
    "    for file in files:\n",
    "        if file.endswith(\"DEREG.txt\")or file.endswith('DEREG.TXT')or file.endswith('Dereg.txt') or file.endswith('Dereg.TXT') or file.endswith('DeReg.txt')or file.endswith('DeReg.TXT'):\n",
    "            path = os.path.join(root, file)\n",
    "            dpath.append(path)\n",
    "\n",
    "#Good Format\n",
    "DEREG17 = pd.read_csv(dpath[7], sep = \",\", index_col=False, skipinitialspace = True,low_memory=False)\n",
    "DEREG18 = pd.read_csv(dpath[8], sep = \",\", index_col=False, skipinitialspace = True,low_memory=False)\n",
    "DEREG19 = pd.read_csv(dpath[9], sep = \",\", index_col=False, skipinitialspace = True,low_memory=False)\n",
    "DEREG20 = pd.read_csv(dpath[10],sep = \",\", index_col=False, skipinitialspace = True,low_memory=False)\n",
    "\n",
    "#Bad Format\n",
    "names = ['N-NUMBER', 'SERIAL-NUMBER', 'MFR-MDL-CODE', 'UNIQUE-ID', 'STATUS-CODE', 'NAME', 'STREET-MAIL', 'STREET2-MAIL', 'CITY-MAIL', 'STATE-ABBREV-MAIL',\n",
    "       'ZIP-CODE-MAIL', 'ENG-MFR-MDL', 'YEAR-MFR', 'CERTIFICATION', 'REGION','FIPS-STATE-CODE',\n",
    "       'COUNTY-MAIL', 'COUNTRY-MAIL', 'AIR-WORTH-DATE', 'DESTROYED-DATE','DESTROYED-IND', 'OTHER-NAMES-CNT', 'OTHER-NAMES', 'CANCEL-DATE',\n",
    "       'MODE-S-CODE', 'EXCEPTION-CODE', 'INDICATOR-GROUP', 'EXP-COUNTRY', 'CANC-REQ-BY', 'LAST-ACT-DATE',\n",
    "       'CERT-ISSUE-DATE', 'SPECIAL-COMMENTS(1)','SPECIAL-COMMENTS(2)','SPECIAL-COMMENTS(3)','SPECIAL-COMMENTS(4)','SPECIAL-COMMENTS(5)', 'STREET-PHYSICAL', 'STREET2-PHYSICAL',\n",
    "       'CITY-PHYSICAL', 'STATE-ABBREV-PHYSICAL', 'ZIP-CODE-PHYSICAL',\n",
    "       'COUNTY-PHYSICAL', 'COUNTRY-PHYSICAL', 'TRADE-NAME-IND', 'KIT-CODE', 'AW-SUS-REV', 'AW-SUS-REV-DATE', 'Unnamed: 48']\n",
    "DEREG10 = pd.read_csv(dpath[0], sep = \",\", names = names, index_col=False, skipinitialspace = True,low_memory=False, encoding='latin1')\n",
    "DEREG11 = pd.read_csv(dpath[1], sep = \",\", names = names, index_col=False, skipinitialspace = True,low_memory=False, encoding='latin1')\n",
    "DEREG12 = pd.read_csv(dpath[2], sep = \",\", names = names, index_col=False, skipinitialspace = True,low_memory=False, encoding='latin1')\n",
    "DEREG13 = pd.read_csv(dpath[3], sep = \",\", names = names, index_col=False, skipinitialspace = True,low_memory=False, encoding='latin1')\n",
    "DEREG14 = pd.read_csv(dpath[4], sep = \",\", names = names, index_col=False, skipinitialspace = True,low_memory=False, encoding='latin1')\n",
    "DEREG15 = pd.read_csv(dpath[5], sep = \",\", names = names, index_col=False, skipinitialspace = True,low_memory=False, encoding='latin1')\n",
    "DEREG16 = pd.read_csv(dpath[6], sep = \",\", names = names, index_col=False, skipinitialspace = True,low_memory=False, encoding='latin1')\n",
    "\n",
    "#Marking datasource \n",
    "DEREG10['YEAR'] = '2010'\n",
    "DEREG11['YEAR'] = '2011'\n",
    "DEREG12['YEAR'] = '2012'\n",
    "DEREG13['YEAR'] = '2013'\n",
    "DEREG14['YEAR'] = '2014'\n",
    "DEREG15['YEAR'] = '2015'\n",
    "DEREG16['YEAR'] = '2016'\n",
    "DEREG17['YEAR'] = '2017'\n",
    "DEREG18['YEAR'] = '2018'\n",
    "DEREG19['YEAR'] = '2019'\n",
    "DEREG20['YEAR'] = '2020'\n",
    "\n",
    "#Concat - badDateform w year, N-NUM adjusted, Trimed&StringallObjects  \n",
    "deregs = [DEREG10, DEREG11, DEREG12, DEREG13, DEREG14, DEREG15, DEREG16,DEREG17,DEREG18,DEREG19,DEREG20]\n",
    "DEREG = pd.concat(deregs,ignore_index = True,sort=False).reset_index(drop=True)\n",
    "DEREG['N-NUMBER'] = 'N' + DEREG['N-NUMBER'].astype(str)\n",
    "DEREG_obj = DEREG.select_dtypes(['object'])\n",
    "DEREG_obj.astype(str)\n",
    "DEREG[DEREG_obj.columns] =DEREG_obj.apply(lambda x: x.str.strip())\n",
    "\n",
    "#DroppedDuplicates - Reg&Acftcode, keeping last\n",
    "DEREG = DEREG.drop_duplicates(subset=['N-NUMBER','MFR-MDL-CODE'], keep='last')\n",
    "DEREG = DEREG.rename(columns={'N-NUMBER':'Registration Number '})\n",
    "\n",
    "# # -------------------------------------------------------------------------------------------\n",
    "# #Concat - Gooddateformat w/o years, Trimed&StringallObjects \n",
    "# DEREG10_16 = pd.read_csv('DEREG10-16.csv',index_col=False,low_memory=False)\n",
    "# DEREG17_20 = pd.concat([DEREG17,DEREG18,DEREG19,DEREG20],ignore_index = True,sort=False).reset_index(drop=True)\n",
    "# DEREG17_20_obj = DEREG17_20.select_dtypes(['object'])\n",
    "# DEREG17_20_obj.astype(str)\n",
    "# DEREG17_20[DEREG17_20_obj.columns] =DEREG17_20_obj.apply(lambda x: x.str.strip())\n",
    "# DEREG17_20 = DEREG17_20.drop_duplicates(subset=['N-NUMBER','MFR-MDL-CODE'], keep='last')\n",
    "# DEREG17_20 = DEREG17_20.rename(columns={'N-NUMBER':'Registration Number '})\n",
    "# #DropDuplicates based on Reg&Acftcode \n",
    "# DEREG2= pd.concat([DEREG10_16,DEREG17_20],ignore_index = True,sort=False).reset_index(drop=True)\n",
    "# DEREG2= DEREG.drop_duplicates(subset=['Registration Number ', 'MFR-MDL-CODE'], keep='last')\n",
    "# # DEREG2['N-NUMBER'] = 'N' + DEREG2['N-NUMBER'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEREG.drop(columns='Unnamed: 38',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEREG.to_csv(\"DEREG.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aircraft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "apath = []\n",
    "for root, dirs, files in os.walk(r\"C:\\Users\\zlin\\FAA_Zoey\\Data Extraction\", topdown=False):\n",
    "    for file in files:\n",
    "        if file.endswith(\"ACFTREF.txt\")or file.endswith('ACFTREF.TXT'):\n",
    "            path = os.path.join(root, file)\n",
    "            apath.append(path)\n",
    "#Good Format\n",
    "ACFTREF17 = pd.read_csv(apath[7], sep = \",\", index_col=False, skipinitialspace = True,low_memory=False)\n",
    "ACFTREF18 = pd.read_csv(apath[8], sep = \",\", index_col=False, skipinitialspace = True,low_memory=False)\n",
    "ACFTREF19 = pd.read_csv(apath[9], sep = \",\", index_col=False, skipinitialspace = True,low_memory=False)\n",
    "ACFTREF20 = pd.read_csv(apath[10], sep = \",\", index_col=False, skipinitialspace = True,low_memory=False)\n",
    "\n",
    "#Bad Format\n",
    "cols = ['MFR','MODEL', 'TYPE-ACFT', 'TYPE-ENG', 'AC-CAT', 'BUILD-CERT-IND', 'NO-ENG', 'NO-SEATS', 'AC-WEIGHT', 'SPEED', 'CODE', 'Unnamed: 11']\n",
    "ACFTREF10 = pd.read_csv(apath[0], sep = \",\", names = cols, index_col=False, skipinitialspace = True,low_memory=False)\n",
    "ACFTREF11 = pd.read_csv(apath[1], sep = \",\", names = cols, index_col=False, skipinitialspace = True,low_memory=False)\n",
    "ACFTREF12 = pd.read_csv(apath[2], sep = \",\", names = cols, index_col=False, skipinitialspace = True,low_memory=False)\n",
    "ACFTREF13 = pd.read_csv(apath[3], sep = \",\", names = cols, index_col=False, skipinitialspace = True,low_memory=False)\n",
    "ACFTREF14 = pd.read_csv(apath[4], sep = \",\", names = cols, index_col=False, skipinitialspace = True,low_memory=False)\n",
    "ACFTREF15 = pd.read_csv(apath[5], sep = \",\", names = cols, index_col=False, skipinitialspace = True,low_memory=False)\n",
    "ACFTREF16 = pd.read_csv(apath[6], sep = \",\", names = cols, index_col=False, skipinitialspace = True,low_memory=False)\n",
    "\n",
    "correctorder = ['CODE', 'MFR', 'MODEL', 'TYPE-ACFT', 'TYPE-ENG', 'AC-CAT','BUILD-CERT-IND', 'NO-ENG', 'NO-SEATS', 'AC-WEIGHT', 'SPEED','Unnamed: 11']\n",
    "ACFTREF10 = ACFTREF10[correctorder]\n",
    "ACFTREF11 = ACFTREF11[correctorder]\n",
    "ACFTREF12 = ACFTREF12[correctorder]\n",
    "ACFTREF13 = ACFTREF13[correctorder]\n",
    "ACFTREF14 = ACFTREF14[correctorder]\n",
    "ACFTREF15 = ACFTREF15[correctorder]\n",
    "ACFTREF16 = ACFTREF16[correctorder]\n",
    "\n",
    "#Aggregate, trimmed\n",
    "acftrefs = [ACFTREF10, ACFTREF11, ACFTREF12, ACFTREF13, ACFTREF14, ACFTREF15, ACFTREF16, ACFTREF17, ACFTREF18, ACFTREF19, ACFTREF20]\n",
    "ACFTREF = pd.concat(acftrefs,ignore_index = True).reset_index(drop=True)\n",
    "ACFTREF_obj = ACFTREF.select_dtypes(['object'])\n",
    "ACFTREF[ACFTREF_obj.columns] =ACFTREF_obj.apply(lambda x: x.str.strip())\n",
    "ACFTREF['CODE'] = ACFTREF['CODE'].astype(str)\n",
    "ACFTREF['CODE'] = ACFTREF['CODE'].str.upper()\n",
    "# ACFTREF = ACFTREF.drop_duplicates(subset='CODE', keep = 'last')\n",
    "ACFTREF = ACFTREF.rename(columns={'CODE':'MFR MDL CODE'})\n",
    "ACFTREF = ACFTREF.drop_duplicates(subset='MFR MDL CODE',keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACFTREF.drop(columns='Unnamed: 11',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACFTREF.to_csv('ACFTREF.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "epath = []\n",
    "for root, dirs, files in os.walk(r\"C:\\Users\\zlin\\FAA_Zoey\\Data Extraction\", topdown=False):\n",
    "    for file in files:\n",
    "        if file.endswith(\"ENGINE.txt\")or file.endswith('ENGINE.TXT'):\n",
    "            path = os.path.join(root, file)\n",
    "            epath.append(path)\n",
    "\n",
    "#Good Format\n",
    "ENGINE17 = pd.read_csv(epath[7], sep = \",\", index_col=False, skipinitialspace = True,low_memory=False)\n",
    "ENGINE18 = pd.read_csv(epath[8], sep = \",\", index_col=False, skipinitialspace = True,low_memory=False)\n",
    "ENGINE19 = pd.read_csv(epath[9], sep = \",\", index_col=False, skipinitialspace = True,low_memory=False)\n",
    "ENGINE20 = pd.read_csv(epath[10],sep = \",\", index_col=False, skipinitialspace = True,low_memory=False)\n",
    "\n",
    "#Bad Format\n",
    "columns = ['MFR', 'MODEL', 'TYPE', 'HORSEPOWER', 'FUEL-CONSUMED','CODE']\n",
    "ENGINE10 = pd.read_csv(epath[0],names = columns,index_col=False, sep = \",\", skipinitialspace = True,low_memory=False)\n",
    "ENGINE11 = pd.read_csv(epath[1],names = columns,index_col=False, sep = \",\", skipinitialspace = True,low_memory=False)\n",
    "ENGINE12 = pd.read_csv(epath[2],names = columns,index_col=False, sep = \",\", skipinitialspace = True,low_memory=False)\n",
    "ENGINE13 = pd.read_csv(epath[3],names = columns,index_col=False, sep = \",\", skipinitialspace = True,low_memory=False)\n",
    "ENGINE14 = pd.read_csv(epath[4],names = columns,index_col=False, sep = \",\", skipinitialspace = True,low_memory=False)\n",
    "ENGINE15 = pd.read_csv(epath[5],names = columns,index_col=False, sep = \",\", skipinitialspace = True,low_memory=False)\n",
    "ENGINE16 = pd.read_csv(epath[6],names = columns,index_col=False, sep = \",\", skipinitialspace = True,low_memory=False)\n",
    "\n",
    "order = ['CODE', 'MFR', 'MODEL', 'TYPE', 'HORSEPOWER','FUEL-CONSUMED']\n",
    "ENGINE10 = ENGINE10[order]\n",
    "ENGINE11 = ENGINE11[order]\n",
    "ENGINE12 = ENGINE12[order]\n",
    "ENGINE13 = ENGINE13[order]\n",
    "ENGINE14 = ENGINE14[order]\n",
    "ENGINE15 = ENGINE15[order]\n",
    "ENGINE16 = ENGINE16[order]\n",
    "\n",
    "#Aggregate\n",
    "engines = [ENGINE10, ENGINE11, ENGINE12, ENGINE13, ENGINE14, ENGINE15, ENGINE16, ENGINE17,ENGINE18, ENGINE19, ENGINE20]\n",
    "ENGINE = pd.concat(engines,ignore_index = True,sort=False).reset_index(drop=True)\n",
    "ENGINE_obj = ENGINE.select_dtypes(['object'])\n",
    "ENGINE[ENGINE_obj.columns] =ENGINE_obj.apply(lambda x: x.str.strip())\n",
    "ENGINE = ENGINE.drop_duplicates(subset='CODE', keep = 'last')\n",
    "ENGINE = ENGINE.rename(columns={'CODE':'ENG MFR MDL','TYPE':'TYPE ENGINE'})\n",
    "\n",
    "ENGINE = ENGINE.drop_duplicates(subset='ENG MFR MDL',keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENGINE.drop(columns='Unnamed: 6',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENGINE.to_csv('ENGINE.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlpath = []\n",
    "for root, dirs, files in os.walk(r\"C:\\Users\\zlin\\FAA_Zoey\\Data Extraction\", topdown=False):\n",
    "    for file in files:\n",
    "        if file.endswith(\"DEALER.txt\")or file.endswith('DEALER.TXT'):\n",
    "            path = os.path.join(root, file)\n",
    "            dlpath.append(path)\n",
    "\n",
    "#Good Format\n",
    "DEALER17 = pd.read_csv(dlpath[7], sep = \",\", index_col=False, skipinitialspace = True)\n",
    "DEALER18 = pd.read_csv(dlpath[8], sep = \",\", index_col=False, skipinitialspace = True)\n",
    "DEALER19 = pd.read_csv(dlpath[9], sep = \",\", index_col=False, skipinitialspace = True)\n",
    "DEALER20 = pd.read_csv(dlpath[10],sep = \",\", index_col=False, skipinitialspace = True)\n",
    "\n",
    "#Bad Format\n",
    "label = (['CERTIFICATE-NUMBER', 'OWNERSHIP', 'CERTIFICATE-DATE','EXPIRATION-DATE', 'EXPIRATION-FLAG', 'CERTIFICATE-ISSUE-COUNT', 'PENDING-ISSUE-COUNT', 'NAME','STREET', 'STREET2', 'CITY', 'STATE-ABBREV', 'ZIP-CODE', 'STREET-BUS', 'STREET2-BUS', 'CITY-BUS', 'STATE-ABBREV-BUS', 'ZIP-CODE-BUS',  'OTHER-NAMES-1', 'OTHER-NAMES-2', 'OTHER-NAMES-3','OTHER-NAMES-4', 'OTHER-NAMES-5', 'OTHER-NAMES-6', 'OTHER-NAMES-7', 'OTHER-NAMES-8', 'OTHER-NAMES-9', 'OTHER-NAMES-10', 'OTHER-NAMES-11','OTHER-NAMES-12', 'OTHER-NAMES-13', 'OTHER-NAMES-14', 'OTHER-NAMES-15','OTHER-NAMES-16', 'OTHER-NAMES-17', 'OTHER-NAMES-18', 'OTHER-NAMES-19','OTHER-NAMES-20', 'OTHER-NAMES-21', 'OTHER-NAMES-22', 'OTHER-NAMES-23','OTHER-NAMES-24', 'OTHER-NAMES-25', 'OTHER-NAMES-26', 'TRADE-NAME-IND', 'Unnamed: 38'])\n",
    "DEALER10 = pd.read_csv(dlpath[0], sep = \",\", names = label, index_col=False, skipinitialspace = True)\n",
    "DEALER11 = pd.read_csv(dlpath[1], sep = \",\", names = label, index_col=False, skipinitialspace = True)\n",
    "DEALER12 = pd.read_csv(dlpath[2], sep = \",\", names = label, index_col=False, skipinitialspace = True)\n",
    "DEALER13 = pd.read_csv(dlpath[3], sep = \",\", names = label, index_col=False, skipinitialspace = True)\n",
    "DEALER14 = pd.read_csv(dlpath[4], sep = \",\", names = label, index_col=False, skipinitialspace = True)\n",
    "DEALER15 = pd.read_csv(dlpath[5], sep = \",\", names = label, index_col=False, skipinitialspace = True)\n",
    "DEALER16 = pd.read_csv(dlpath[6], sep = \",\", names = label, index_col=False, skipinitialspace = True)\n",
    "\n",
    "#Aggregate\n",
    "dealers = [DEALER10, DEALER11, DEALER12, DEALER13, DEALER14, DEALER15, DEALER16,DEALER17,DEALER18, DEALER19, DEALER20]\n",
    "DEALER = pd.concat(dealers, axis = 0, ignore_index=True, sort = False).reset_index(drop=True)\n",
    "DEALER = DEALER.drop_duplicates(subset='CERTIFICATE-NUMBER', keep = 'last')\n",
    "DEALER_obj = DEALER.select_dtypes(['object'])\n",
    "DEALER[DEALER_obj.columns] =DEALER_obj.apply(lambda x: x.str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEALER.drop(columns='Unnamed: 38',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEALER.to_csv('DEALER.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpath = []\n",
    "for root, dirs, files in os.walk(r\"C:\\Users\\zlin\\FAA_Zoey\\Data Extraction\", topdown=False):\n",
    "    for file in files:\n",
    "        if file.endswith(\"RESERVED.txt\")or file.endswith('RESERVED.TXT'):\n",
    "            path = os.path.join(root, file)\n",
    "            rpath.append(path)\n",
    "            \n",
    "#Good Format\n",
    "RESERVED17 = pd.read_csv(rpath[0], sep = \",\", index_col=False, skipinitialspace = True,low_memory=False)\n",
    "RESERVED18 = pd.read_csv(rpath[1], sep = \",\", index_col=False, skipinitialspace = True,low_memory=False)\n",
    "RESERVED19 = pd.read_csv(rpath[2], sep = \",\", index_col=False, skipinitialspace = True,low_memory=False)\n",
    "RESERVED20 = pd.read_csv(rpath[3], sep = \",\", index_col=False, skipinitialspace = True,low_memory=False)\n",
    "\n",
    "#Aggregate\n",
    "reserves = [RESERVED17,RESERVED18, RESERVED19, RESERVED20]\n",
    "RESERVED = pd.concat(reserves,ignore_index = True).reset_index(drop=True)\n",
    "RESERVED = RESERVED.drop_duplicates(subset='N-NUMBER', keep = 'last')\n",
    "RESERVED_obj = RESERVED.select_dtypes(['object'])\n",
    "RESERVED[RESERVED_obj.columns] =RESERVED_obj.apply(lambda x: x.str.strip())\n",
    "RESERVED = RESERVED.rename(columns={'N-NUMBER':'Registration Number '})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESERVED.drop(columns='Unnamed: 11',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESERVED.to_csv('RESERVED.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Docindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
